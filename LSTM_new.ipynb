{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "#from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "#from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((15840, 1, 1), (15840,), (2920, 1, 1), (2920,))\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_5 (LSTM)                    (32, 1, 20)           1760        lstm_input_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (32, 20)              3280        lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (32, 1)               21          lstm_6[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 5061\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "dataset = pd.read_csv('karl7.csv',low_memory=False, parse_dates= ['Timestamp'])\n",
    "dataset = dataset.set_index('Timestamp')\n",
    "dataset1 = pd.DataFrame()\n",
    "'''Resample data for every 1 minute'''\n",
    "dataset1['States'] = dataset['States'].resample('60s').count()\n",
    "# save to file\n",
    "\n",
    "dataset1.to_csv('data.csv')\n",
    "dataset1.shape\n",
    "\n",
    "dataset = read_csv('data.csv', header=0, index_col=0)\n",
    "dataset = pd.concat([dataset, dataset.shift(1)], axis=1)\n",
    "dataset.dropna(inplace=True)\n",
    "values = dataset.values\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "#pyplot.plot(scaled[:,1])\n",
    "\n",
    "\n",
    "# split into train and test set\n",
    "\n",
    "n_train_hours = 11 * 24 * 60\n",
    "train = scaled[:n_train_hours, :]\n",
    "test = scaled[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# configure network\n",
    "n_batch = 32\n",
    "n_epoch = 1\n",
    "n_neurons = 20\n",
    "\n",
    "'''Define the model'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, return_sequences=True, batch_input_shape=(n_batch, train_X.shape[1], train_X.shape[2])))\n",
    "model.add(LSTM(n_neurons))\n",
    "model.add(Dense(1))\n",
    "\n",
    "'''compile the model'''\n",
    "model.compile(loss= 'mse', optimizer= 'adam', metrics=['mean_squared_error'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15840 samples, validate on 2920 samples\n",
      "Epoch 1/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 2/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 3/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 4/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 5/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 6/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 7/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 9/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 10/10\n",
      "15840/15840 [==============================] - 2s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epoch):\n",
    "    model.fit(train_X, train_y, validation_data=(test_X, test_y), batch_size=n_batch, verbose=1, shuffle=False)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Predictor Error'''\n",
    "\n",
    "yhat = model.predict(train_X, batch_size=n_batch)\n",
    "for i in range(len(train_y)):\n",
    "    e = train_y[i] - yhat[i]\n",
    "    #print('Error: %f' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
